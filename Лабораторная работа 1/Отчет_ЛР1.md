# Отчет по лабораторной работе: kNN и линейная регрессия

## 1. Цель работы
1. Реализовать и исследовать метод **k ближайших соседей (kNN)** для задачи классификации.  
2. Построить **линейную регрессию** для задачи прогнозирования непрерывной целевой переменной и оценить качество по метрикам (MSE, RMSE, MAE, R²).  
3. Выполнить предобработку данных (кодирование категориальных признаков, масштабирование числовых) и показать, как это влияет на качество моделей.  
4. Дополнительно рассмотреть регуляризацию (LassoCV) и сравнить ее с обычной LinearRegression.

---

## 2. Используемые данные и библиотеки
### 2.1. Данные для классификации (Penguins)
В части kNN используется датасет пингвинов (признаки острова, пола, измерений и т.п.) с целевой переменной `Species` (3 класса).  
После очистки от пропусков и кодирования итоговый набор для обучения имеет **324 объекта и 10 признаков**, целевая переменная — `Speciesencoded` со значениями `0, 1, 2`.  
Распределение классов (кол-во объектов): `Chinstrap=67`, `Gentoo=118`, `Adelie=139`.

### 2.2. Данные для регрессии (Diamonds)
В части линейной регрессии используется `diamonds.csv` с целевой переменной `price`; категориальные признаки кодируются one-hot, затем формируются `X` и `y` и выполняется разбиение на train/test.

### 2.3. Основные библиотеки
В работе используются `pandas`, `numpy`, `scikit-learn` (train_test_split, StandardScaler, KNeighborsClassifier, LinearRegression, LassoCV, метрики), а также `mlxtend` для визуализации областей решений kNN.

---

## 3. Предобработка данных

### 3.1. Кодирование целевого класса и категориальных признаков (Penguins)
- `Species` преобразуется в коды по словарю: `Chinstrap→0`, `Gentoo→1`, `Adelie→2`.  
- `Island` кодируется LabelEncoder в `Islandencoded`.  
- Признаки вроде `Clutch Completion`, `Sex` переводятся в числовой формат через маппинг значений.

### 3.2. Разбиение train/test
Данные делятся на **70% train / 30% test** с `random_state=42` и `stratify=y`, чтобы сохранить доли классов.  
Размерности: `Xtrain = (226, 10)`, `Xtest = (98, 10)`; доли классов в train/test близки к исходным.

### 3.3. Масштабирование признаков (важно для kNN)
Для kNN берутся 2 признака:
- `Flipper Length (mm)`
- `Body Mass (g)`

Далее применяется `StandardScaler`: средние значения приводятся к ~0, стандартные отклонения к ~1.  
Это важно, потому что kNN использует расстояния (в ноутбуке — Euclidean), и без масштабирования признак с большими числами (масса) «перетянет» модель.

### 3.4. Предобработка для регрессии (Diamonds)
- Категориальные признаки (`cut`, `color`, `clarity`) кодируются one-hot (`pd.get_dummies`).  
- Числовые признаки (`carat`, `x`, `y`, `z`, `depth`, `table`) масштабируются StandardScaler.  
- Проверяется, что train/test похожи по средним числовых признаков и по долям категорий (one-hot), то есть разбиение адекватное.

---

## 4. Эксперимент 1: kNN-классификация

### 4.1. Постановка
Обучается `KNeighborsClassifier(metric="euclidean")` на стандартизированных признаках `Flipper Length` и `Body Mass`.  
Подбирается число соседей из списка: `k = [1, 3, 5, 10, 15, 25]`.

### 4.2. Результаты (accuracy)
| k | Train Accuracy | Test Accuracy |
|---:|---:|---:|
| 1  | 0.9690 | 0.7551 |
| 3  | 0.8540 | 0.7551 |
| 5  | 0.8319 | 0.7755 |
| 10 | 0.8274 | 0.7755 |
| 15 | 0.8142 | 0.7551 |
| 25 | 0.7965 | 0.8367 |

### 4.3. Анализ
- При `k=1` точность на обучении очень высокая (0.9690), но на тесте существенно ниже (0.7551) — это признак **переобучения**.  
- При увеличении `k` train accuracy снижается, но test accuracy сначала растет.  
- Лучший тестовый результат среди проверенных значений — **k=25** (test accuracy = 0.8367).

### 4.4. Визуализация областей решений
Дополнительно строятся decision regions для разных `k` с помощью `mlxtend.plotting.plot_decision_regions`, чтобы визуально сравнить «гладкость» границ при разных `k`.

---

## 5. Эксперимент 2: Линейная регрессия (Diamonds)

### 5.1. Постановка
Строится модель `LinearRegression` на стандартизированных числовых признаках и one-hot категориальных признаках.  
Считаются метрики качества на train и test:
- MSE
- RMSE
- MAE
- R²

Также строится таблица коэффициентов и берутся топ признаков по |coef|.

### 5.2. Интерпретация коэффициентов
По коэффициентам видно:
- `carat` имеет самый большой положительный коэффициент (примерно **5338.62**), то есть рост карата сильнее всего увеличивает прогноз цены.  
- Некоторые уровни `clarity` и `color` дают отрицательные/положительные сдвиги относительно базового уровня one-hot кодирования (например, `clarityI1` — заметно отрицательный коэффициент около **-3889.61**).  
- Перехват (intercept) выводится примерно **3385.47**.  

Важно: из-за стандартизации числовых признаков коэффициенты читаются как вклад изменения признака на 1 стандартное отклонение (для числовых колонок).

### 5.3. Диагностика качества
Строятся:
- scatter “y_true vs y_pred” для train/test;  
- гистограммы ошибок (residuals);  
- статистики ошибок (mean/std/min/max) и оценка разницы MSE test-train как индикатор переобучения.

---

## 6. Эксперимент 3: Lasso (LassoCV)

### 6.1. Идея
Lasso добавляет L1-регуляризацию и может занулять коэффициенты, то есть выполнять отбор признаков (sparse model).  
Применяется `LassoCV`: подбирается `alpha` по кросс-валидации, визуально анализируется зависимость MSE от `alpha`.

### 6.2. Сравнение с LinearRegression
Считаются метрики для LinearRegression и Lasso, затем сравниваются MSE и R², а также число ненулевых коэффициентов (у Lasso их меньше).  
Это демонстрирует идею регуляризации: сделать модель проще и потенциально устойчивее на тестовых данных.

---

## 7. Выводы
1. Для kNN подтвержден эффект: малые `k` дают высокую точность на train и более низкую на test (переобучение), а увеличение `k` делает модель более устойчивой; в переборе лучший test accuracy получен при `k=25` (0.8367).  
2. Масштабирование признаков StandardScaler для kNN критично, так как расстояния чувствительны к масштабу признаков.  
3. Линейная регрессия на данных diamonds после one-hot и стандартизации дает интерпретируемую модель: по коэффициентам видно, что `carat` — главный фактор цены, а уровни качества/цвета/чистоты влияют как сдвиги относительно базовых категорий.  
4. LassoCV показывает пример регуляризации и отбора признаков: модель становится более разреженной и может вести себя стабильнее.

---

## 8. Приложение: ключевые результаты
- Размер датасета Penguins после очистки/кодирования: 324 объектов, 10 признаков; train/test = 226/98.  
- kNN accuracy (train/test) для `k=[1,3,5,10,15,25]`, лучший тест — `k=25` (0.8367).  
- Топ коэффициентов LinearRegression: `carat` ≈ 5338.62, `clarityI1` ≈ -3889.61 и т.д.; intercept ≈ 3385.47.
