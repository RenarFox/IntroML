# Отчет по лабораторной работе: kNN и линейная регрессия
*(по ноутбуку `hw_knn_linreg-2.ipynb`)* [file:1]

## 1. Цель работы
1. Реализовать и исследовать метод **k ближайших соседей (kNN)** для задачи классификации. [file:1]  
2. Построить **линейную регрессию** для задачи прогнозирования непрерывной целевой переменной и оценить качество по метрикам (MSE, RMSE, MAE, R²). [file:1]  
3. Выполнить предобработку данных (кодирование категориальных признаков, масштабирование числовых) и показать, как это влияет на качество моделей. [file:1]  
4. Дополнительно рассмотреть регуляризацию (LassoCV) и сравнить ее с обычной LinearRegression. [file:1]

---

## 2. Используемые данные и библиотеки
### 2.1. Данные для классификации (Penguins)
В части kNN используется датасет пингвинов (признаки острова, пола, измерений и т.п.) с целевой переменной `Species` (3 класса). [file:1]  
После очистки от пропусков и кодирования итоговый набор для обучения имеет **324 объекта и 10 признаков**, целевая переменная — `Speciesencoded` со значениями `0,1,2`. [file:1]  
Распределение классов (кол-во объектов): `Chinstrap=67`, `Gentoo=118`, `Adelie=139`. [file:1]

### 2.2. Данные для регрессии (Diamonds)
В части линейной регрессии используется `diamonds.csv` с целевой переменной `price`; категориальные признаки кодируются one-hot, затем формируются `X` и `y` и выполняется разбиение на train/test. [file:1]  

### 2.3. Основные библиотеки
В работе используются `pandas`, `numpy`, `scikit-learn` (train_test_split, StandardScaler, KNeighborsClassifier, LinearRegression, LassoCV, метрики), а также `mlxtend` для визуализации областей решений kNN. [file:1]

---

## 3. Предобработка данных

### 3.1. Кодирование целевого класса и категориальных признаков (Penguins)
- `Species` преобразуется в коды по словарю: `Chinstrap→0`, `Gentoo→1`, `Adelie→2`. [file:1]  
- `Island` кодируется LabelEncoder в `Islandencoded`. [file:1]  
- Признаки вроде `Clutch Completion`, `Sex` переводятся в числовой формат через маппинг значений. [file:1]

### 3.2. Разбиение train/test
Данные делятся на **70% train / 30% test** с `random_state=42` и `stratify=y`, чтобы сохранить доли классов. [file:1]  
Размерности: `Xtrain = (226, 10)`, `Xtest = (98, 10)`; доли классов в train/test близки к исходным. [file:1]

### 3.3. Масштабирование признаков (важно для kNN)
Для kNN берутся 2 признака:
- `Flipper Length (mm)`
- `Body Mass (g)` [file:1]

Далее применяется `StandardScaler`: средние значения приводятся к ~0, стандартные отклонения к ~1. [file:1]  
Это важно, потому что kNN использует расстояния (в ноутбуке — Euclidean), и без масштабирования признак с большими числами (масса) «перетянет» модель. [file:1]

### 3.4. Предобработка для регрессии (Diamonds)
- Категориальные признаки (`cut`, `color`, `clarity`) кодируются one-hot (`pd.get_dummies`). [file:1]  
- Числовые признаки (`carat`, `x`, `y`, `z`, `depth`, `table`) масштабируются StandardScaler. [file:1]  
- Печатается сравнение средних train/test по числовым признакам и долей по нескольким one-hot колонкам — различия небольшие, что подтверждает корректность разбиения. [file:1]

---

## 4. Эксперимент 1: kNN-классификация

### 4.1. Постановка
Обучается `KNeighborsClassifier(metric="euclidean")` на стандартизированных признаках `Flipper Length` и `Body Mass`. [file:1]  
Подбирается число соседей из списка: `k = [1, 3, 5, 10, 15, 25]`. [file:1]

### 4.2. Результаты (accuracy)
Из вывода ноутбука: [file:1]

| k | Train Accuracy | Test Accuracy |
|---:|---:|---:|
| 1  | 0.9690 | 0.7551 |
| 3  | 0.8540 | 0.7551 |
| 5  | 0.8319 | 0.7755 |
| 10 | 0.8274 | 0.7755 |
| 15 | 0.8142 | 0.7551 |
| 25 | 0.7965 | 0.8367 |

[file:1]

### 4.3. Анализ
- При `k=1` точность на обучении очень высокая (0.9690), но на тесте существенно ниже (0.7551) — это признак **переобучения**: модель запоминает обучающую выборку и хуже обобщает. [file:1]  
- При увеличении `k` train accuracy снижается (модель становится «грубее»), но test accuracy сначала растет. [file:1]  
- Лучший тестовый результат среди проверенных значений — **k=25** (test accuracy = 0.8367). [file:1]  

### 4.4. Визуализация областей решений
В ноутбуке дополнительно строятся decision regions для разных `k` с помощью `mlxtend.plotting.plot_decision_regions`, что позволяет визуально увидеть, как при росте `k` границы становятся более гладкими и устойчивыми. [file:1]

---

## 5. Эксперимент 2: Линейная регрессия (Diamonds)

### 5.1. Постановка
Строится модель `LinearRegression` на стандартизированных числовых признаках и one-hot категориальных признаках. [file:1]  
Считаются метрики качества на train и test:
- MSE
- RMSE
- MAE
- R² [file:1]

Также строится таблица коэффициентов и берутся топ признаков по |coef| (важность в линейной модели). [file:1]

### 5.2. Интерпретация коэффициентов
По выводу коэффициентов видно:
- `carat` имеет самый большой положительный коэффициент (примерно **5338.62**), то есть рост карата увеличивает прогноз цены сильнее всего. [file:1]  
- Некоторые уровни `clarity` и `color` дают отрицательные/положительные сдвиги относительно базового уровня one-hot кодирования (например, `clarityI1` — заметно отрицательный коэффициент около **-3889.61**). [file:1]  
- Геометрические признаки (`x`, `y`, `z`) и параметры (`depth`, `table`) тоже влияют, но обычно слабее, чем `carat` и часть категориальных. [file:1]  
- В ноутбуке выводится intercept (примерно **3385.47**). [file:1]

*(Важно: коэффициенты интерпретируются корректно с учетом стандартизации числовых признаков: изменение на 1 “стандартное отклонение” соответствует изменению предсказания на величину коэффициента.)* [file:1]

### 5.3. Диагностика качества
В ноутбуке строятся:
- scatter “y_true vs y_pred” для train/test; [file:1]  
- гистограммы ошибок (residuals); [file:1]  
- статистики ошибок (mean/std/min/max) и оценка разницы MSE test-train как индикатор переобучения. [file:1]  

---

## 6. Эксперимент 3: Lasso (LassoCV)

### 6.1. Идея
Lasso добавляет L1-регуляризацию и может занулять коэффициенты, то есть выполнять отбор признаков (sparse model). [file:1]  
В ноутбуке применяется `LassoCV`: подбирается `alpha` по кросс-валидации, строится график зависимости MSE от `alpha`, выбирается оптимум. [file:1]

### 6.2. Сравнение с LinearRegression
В ноутбуке рассчитываются метрики для LinearRegression и Lasso, затем печатается относительное улучшение/ухудшение MSE и изменение R², а также сравнивается число ненулевых коэффициентов (у Lasso их меньше). [file:1]  
Это демонстрирует, что Lasso может дать более компактную модель и потенциально улучшить обобщение на тесте. [file:1]

---

## 7. Выводы
1. Для kNN подтвержден важный эффект: малые `k` дают высокую точность на train и более низкую на test (переобучение), а увеличение `k` делает модель более устойчивой; в проведенном переборе лучший test accuracy получен при `k=25` (0.8367). [file:1]  
2. Масштабирование признаков StandardScaler для kNN критично, так как расстояния чувствительны к масштабу признаков. [file:1]  
3. Линейная регрессия на данных diamonds после one-hot и стандартизации дает интерпретируемую модель: по коэффициентам видно, что `carat` — главный фактор цены, а уровни качества/цвета/чистоты влияют как сдвиги относительно базовых категорий. [file:1]  
4. LassoCV показывает пример регуляризации и отбора признаков: модель становится более разреженной (меньше ненулевых коэффициентов) и может вести себя стабильнее. [file:1]

---

## 8. Приложение: ключевые фрагменты результатов
- Размер датасета Penguins после очистки/кодирования: 324 объектов, 10 признаков; train/test = 226/98. [file:1]  
- kNN accuracy (train/test) для `k=[1,3,5,10,15,25]`, лучший тест — `k=25` (0.8367). [file:1]  
- Топ коэффициентов LinearRegression: `carat` ≈ 5338.62, `clarityI1` ≈ -3889.61, `clarityIF` ≈ 1569.43 и т.д.; intercept ≈ 3385.47. [file:1]
